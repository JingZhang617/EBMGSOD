import os
import cv2
import torch.nn as nn
import torch
import numpy as np
from torch.autograd import Variable
import torch.nn.functional as F
import random

fx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]).astype(np.float32)
fy = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]).astype(np.float32)
fx = np.reshape(fx, (1, 1, 3, 3))
fy = np.reshape(fy, (1, 1, 3, 3))
fx = Variable(torch.from_numpy(fx)).cuda()
fy = Variable(torch.from_numpy(fy)).cuda()
contour_th = 1.5

def adjust_lr(optimizer, init_lr, epoch, decay_rate=0.1, decay_epoch=5):
    decay = decay_rate ** (epoch // decay_epoch)
    for param_group in optimizer.param_groups:
        param_group['lr'] *= decay

def label_edge_prediction(label):
    # convert label to edge
    label = label.gt(0.5).float()
    label = F.pad(label, (1, 1, 1, 1), mode='replicate')
    label_fx = F.conv2d(label, fx)
    label_fy = F.conv2d(label, fy)
    label_grad = torch.sqrt(torch.mul(label_fx, label_fx) + torch.mul(label_fy, label_fy))
    label_grad = torch.gt(label_grad, contour_th).float()

    return label_grad

def clip_gradient(optimizer, grad_clip):
    for group in optimizer.param_groups:
        for param in group['params']:
            if param.grad is not None:
                param.grad.data.clamp_(-grad_clip, grad_clip)


def adjust_lr(optimizer, init_lr, epoch, decay_rate=0.1, decay_epoch=5):
    decay = decay_rate ** (epoch // decay_epoch)
    for param_group in optimizer.param_groups:
        param_group['lr'] *= decay


def truncated_normal_(tensor, mean=0, std=1):
    size = tensor.shape
    tmp = tensor.new_empty(size + (4,)).normal_()
    valid = (tmp < 2) & (tmp > -2)
    ind = valid.max(-1, keepdim=True)[1]
    tensor.data.copy_(tmp.gather(-1, ind).squeeze(-1))
    tensor.data.mul_(std).add_(mean)


def init_weights(m):
    if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:
        nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')
        #nn.init.normal_(m.weight, std=0.001)
        #nn.init.normal_(m.bias, std=0.001)
        truncated_normal_(m.bias, mean=0, std=0.001)


def init_weights_orthogonal_normal(m):
    if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:
        nn.init.orthogonal_(m.weight)
        truncated_normal_(m.bias, mean=0, std=0.001)
        #nn.init.normal_(m.bias, std=0.001)


def l2_regularisation(m):
    l2_reg = None

    for W in m.parameters():
        if l2_reg is None:
            l2_reg = W.norm(2)
        else:
            l2_reg = l2_reg + W.norm(2)
    return l2_reg


class AvgMeter(object):
    def __init__(self, num=40):
        self.num = num
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0
        self.losses = []

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count
        self.losses.append(val)

    def show(self):
        a = len(self.losses)
        b = np.maximum(a-self.num, 0)
        c = self.losses[b:]

        return torch.mean(torch.stack(c))


def set_seed(seed=1024):
    random.seed(seed)
    # os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    # torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.
    # torch.backends.cudnn.benchmark = False
    # torch.backends.cudnn.deterministic = True


def visualize_all(in_pred, in_gt, path):
    for kk in range(in_pred.shape[0]):
        pred, gt = in_pred[kk, :, :, :], in_gt[kk, :, :, :]
        pred = (pred.detach().cpu().numpy().squeeze()*255.0).astype(np.uint8)
        gt = (gt.detach().cpu().numpy().squeeze()*255.0).astype(np.uint8)
        cat_img = cv2.hconcat([pred, gt])
        save_path = path + '/vis_temp/'   
        # Save vis images this temp folder, based on this experiment's folder.
        if not os.path.exists(save_path):
            os.makedirs(save_path)
        name = '{:02d}_cat.png'.format(kk)
        cv2.imwrite(save_path + name, cat_img)

def visualize_all3(in_pred, edge_pred, in_gt, path):
    for kk in range(in_pred.shape[0]):
        pred, edge, gt = in_pred[kk, :, :, :], edge_pred[kk, :, :, :], in_gt[kk, :, :, :]
        pred = (pred.detach().cpu().numpy().squeeze()*255.0).astype(np.uint8)
        edge = (edge.detach().cpu().numpy().squeeze()*255.0).astype(np.uint8)
        gt = (gt.detach().cpu().numpy().squeeze() * 255.0).astype(np.uint8)
        cat_img = cv2.hconcat([pred, edge, gt])
        save_path = path + '/vis_temp/'
        # Save vis images this temp folder, based on this experiment's folder.
        if not os.path.exists(save_path):
            os.makedirs(save_path)
        name = '{:02d}_cat.png'.format(kk)
        cv2.imwrite(save_path + name, cat_img)

def visualize_all4(in_pred, edge_pred, dis_pred, in_gt, path):
    for kk in range(in_pred.shape[0]):
        pred, edge, dis, gt = in_pred[kk, :, :, :], edge_pred[kk, :, :, :], dis_pred[kk, :, :, :], in_gt[kk, :, :, :]
        pred = (pred.detach().cpu().numpy().squeeze()*255.0).astype(np.uint8)
        edge = (edge.detach().cpu().numpy().squeeze()*255.0).astype(np.uint8)
        dis = (dis.detach().cpu().numpy().squeeze() * 255.0).astype(np.uint8)
        gt = (gt.detach().cpu().numpy().squeeze() * 255.0).astype(np.uint8)
        cat_img = cv2.hconcat([pred, edge, dis, gt])
        save_path = path + '/vis_temp/'
        # Save vis images this temp folder, based on this experiment's folder.
        if not os.path.exists(save_path):
            os.makedirs(save_path)
        name = '{:02d}_cat.png'.format(kk)
        cv2.imwrite(save_path + name, cat_img)
